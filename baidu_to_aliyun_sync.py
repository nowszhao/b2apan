#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç™¾åº¦äº‘ç›˜åˆ°é˜¿é‡Œäº‘ç›˜æ–‡ä»¶å¤¹åŒæ­¥è„šæœ¬
æ”¯æŒ Linux CentOS ç³»ç»Ÿ
"""

import os
import sys
import json
import time
import hashlib
import logging
from pathlib import Path
from typing import Dict, List, Optional, Set
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import pickle

# å¯¼å…¥æ–°çš„ç™¾åº¦ç½‘ç›˜å®¢æˆ·ç«¯
try:
    from baidu_client_pcs import BaiduPanClientPCS
    USE_BAIDUPCS = True
except ImportError:
    USE_BAIDUPCS = False
    logger.warning("baidupcs-py æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸå§‹æ–¹æ³•ï¼ˆå¯èƒ½ä¼šé‡åˆ°ä¸‹è½½é™åˆ¶ï¼‰")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,  # INFO çº§åˆ«ï¼Œç®€æ´æ¸…æ™°
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('sync.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# å¦‚æœéœ€è¦è°ƒè¯•ï¼Œå¯ä»¥è®¾ç½®ä¸º DEBUG
# logger.setLevel(logging.DEBUG)


class BaiduPanClient:
    """ç™¾åº¦ç½‘ç›˜å®¢æˆ·ç«¯"""
    
    def __init__(self, cookie: str = None, access_token: str = None):
        """
        åˆå§‹åŒ–ç™¾åº¦ç½‘ç›˜å®¢æˆ·ç«¯
        :param cookie: ç™¾åº¦ç½‘ç›˜ Cookieï¼ˆæ¨èï¼‰
        :param access_token: ç™¾åº¦ç½‘ç›˜ Access Tokenï¼ˆå¤‡ç”¨ï¼‰
        """
        self.cookie = cookie
        self.access_token = access_token
        self.base_url = "https://pan.baidu.com/rest/2.0/xpan"
        self.web_url = "https://pan.baidu.com"
        
        # å¦‚æœä½¿ç”¨ Cookieï¼Œéœ€è¦æå– BDUSS
        if cookie and not access_token:
            self._extract_bduss()
    
    def _extract_bduss(self):
        """ä» Cookie ä¸­æå– BDUSS"""
        try:
            for item in self.cookie.split(';'):
                item = item.strip()
                if item.startswith('BDUSS='):
                    self.bduss = item.split('=', 1)[1]
                    logger.info("æˆåŠŸæå– BDUSS")
                    return
            logger.warning("Cookie ä¸­æœªæ‰¾åˆ° BDUSS")
        except Exception as e:
            logger.error(f"æå– BDUSS å¤±è´¥: {str(e)}")
    
    def _get_headers(self) -> Dict:
        """è·å–è¯·æ±‚å¤´"""
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://pan.baidu.com/disk/main"
        }
        if self.cookie:
            headers["Cookie"] = self.cookie
        return headers
        
    def list_files(self, dir_path: str = "/", recursion: int = 0) -> List[Dict]:
        """åˆ—å‡ºç›®å½•ä¸‹çš„æ–‡ä»¶"""
        logger.debug(f"åˆ—å‡ºæ–‡ä»¶: {dir_path}, é€’å½’: {recursion}")
        
        # ä½¿ç”¨ Cookie æ–¹å¼
        if self.cookie:
            url = f"{self.web_url}/api/list"
            params = {
                "dir": dir_path,
                "num": 1000,
                "order": "name",
                "desc": 0,
                "web": 1
                # ä¸è®¾ç½® folder å‚æ•°,è·å–æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
            }
            
            try:
                logger.debug(f"è¯·æ±‚ç™¾åº¦äº‘ç›˜ API: {url}")
                response = requests.get(url, params=params, headers=self._get_headers(), timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if data.get("errno") == 0:
                    file_list = data.get("list", [])
                    logger.debug(f"è·å–åˆ° {len(file_list)} ä¸ªé¡¹ç›®")
                    
                    # å¦‚æœéœ€è¦é€’å½’ï¼Œè·å–å­æ–‡ä»¶å¤¹å†…å®¹
                    if recursion:
                        all_files = file_list.copy()
                        folders = [f for f in file_list if f.get("isdir") == 1]
                        logger.debug(f"éœ€è¦é€’å½’ {len(folders)} ä¸ªå­æ–‡ä»¶å¤¹")
                        for folder in folders:
                            logger.debug(f"é€’å½’è·å–: {folder.get('path')}")
                            sub_files = self.list_files(folder.get("path"), recursion)
                            all_files.extend(sub_files)
                        logger.debug(f"é€’å½’å®Œæˆï¼Œæ€»å…± {len(all_files)} ä¸ªé¡¹ç›®")
                        return all_files
                    
                    return file_list
                else:
                    logger.error(f"ç™¾åº¦äº‘ç›˜åˆ—è¡¨è·å–å¤±è´¥: {data.get('errmsg', 'æœªçŸ¥é”™è¯¯')}")
                    return []
            except Exception as e:
                logger.error(f"ç™¾åº¦äº‘ç›˜APIè°ƒç”¨å¤±è´¥: {str(e)}")
                return []
        
        # ä½¿ç”¨ Access Token æ–¹å¼ï¼ˆå¤‡ç”¨ï¼‰
        else:
            url = f"{self.base_url}/file"
            params = {
                "method": "list",
                "access_token": self.access_token,
                "dir": dir_path,
                "recursion": recursion,
                "web": 1
            }
            
            try:
                response = requests.get(url, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if data.get("errno") == 0:
                    return data.get("list", [])
                else:
                    logger.error(f"ç™¾åº¦äº‘ç›˜åˆ—è¡¨è·å–å¤±è´¥: {data.get('errmsg', 'æœªçŸ¥é”™è¯¯')}")
                    return []
            except Exception as e:
                logger.error(f"ç™¾åº¦äº‘ç›˜APIè°ƒç”¨å¤±è´¥: {str(e)}")
                return []
    
    def get_download_link(self, fs_id: int) -> Optional[str]:
        """è·å–æ–‡ä»¶ä¸‹è½½é“¾æ¥"""
        # ä½¿ç”¨ Cookie æ–¹å¼
        if self.cookie:
            # ä½¿ç”¨ /api/filemetas æ¥å£è·å–ä¸‹è½½é“¾æ¥
            url = f"{self.web_url}/api/filemetas"
            params = {
                "fsids": json.dumps([fs_id]),
                "dlink": 1,
                "web": 1
            }
            
            try:
                logger.debug(f"è¯·æ±‚ä¸‹è½½é“¾æ¥: fs_id={fs_id}")
                response = requests.get(url, params=params, headers=self._get_headers(), timeout=30)
                logger.debug(f"å“åº”çŠ¶æ€ç : {response.status_code}")
                
                data = response.json()
                
                if data.get("errno") == 0:
                    info_list = data.get("info", [])
                    if info_list and len(info_list) > 0:
                        dlink = info_list[0].get("dlink")
                        if dlink:
                            logger.debug(f"æˆåŠŸè·å–ä¸‹è½½é“¾æ¥: {dlink[:100]}...")
                            return dlink
                        else:
                            logger.error(f"å“åº”ä¸­æ²¡æœ‰ dlink å­—æ®µ")
                    else:
                        logger.error(f"å“åº”ä¸­æ²¡æœ‰ info åˆ—è¡¨")
                else:
                    logger.error(f"è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: errno={data.get('errno')}, errmsg={data.get('errmsg', 'æœªçŸ¥é”™è¯¯')}")
                return None
            except Exception as e:
                logger.error(f"è·å–ä¸‹è½½é“¾æ¥å¼‚å¸¸: {str(e)}")
                return None
        
        # ä½¿ç”¨ Access Token æ–¹å¼ï¼ˆå¤‡ç”¨ï¼‰
        else:
            url = f"{self.base_url}/file"
            params = {
                "method": "filemetas",
                "access_token": self.access_token,
                "fsids": json.dumps([fs_id]),
                "dlink": 1
            }
            
            try:
                response = requests.get(url, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if data.get("errno") == 0 and data.get("list"):
                    return data["list"][0].get("dlink")
                return None
            except Exception as e:
                logger.error(f"è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: {str(e)}")
                return None
    
    def download_file(self, download_url: str, save_path: str) -> bool:
        """ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°"""
        # ç™¾åº¦ç½‘ç›˜ä¸‹è½½éœ€è¦ç‰¹å®šçš„è¯·æ±‚å¤´
        headers = {
            "User-Agent": "pan.baidu.com",  # å…³é”®ï¼šä½¿ç”¨ç™¾åº¦ç½‘ç›˜çš„ User-Agent
            "Referer": "https://pan.baidu.com/",
            "Cookie": self.cookie if self.cookie else ""
        }
        
        try:
            response = requests.get(download_url, headers=headers, stream=True, timeout=60)
            response.raise_for_status()
            
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            logger.info(f"æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {save_path}")
            return True
        except Exception as e:
            logger.error(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥ {save_path}: {str(e)}")
            return False


class AliyunPanClient:
    """é˜¿é‡Œäº‘ç›˜å®¢æˆ·ç«¯"""
    
    def __init__(self, cookie: str = None, refresh_token: str = None, access_token: str = None, drive_id: str = None):
        """
        åˆå§‹åŒ–é˜¿é‡Œäº‘ç›˜å®¢æˆ·ç«¯
        :param cookie: é˜¿é‡Œäº‘ç›˜ Cookieï¼ˆå¯é€‰ï¼‰
        :param refresh_token: é˜¿é‡Œäº‘ç›˜ Refresh Tokenï¼ˆæ¨èï¼‰
        :param access_token: é˜¿é‡Œäº‘ç›˜ Access Tokenï¼ˆå¯é€‰ï¼Œé…åˆ drive_id ä½¿ç”¨ï¼‰
        :param drive_id: é˜¿é‡Œäº‘ç›˜ Drive IDï¼ˆä½¿ç”¨ access_token æ—¶å¿…éœ€ï¼‰
        """
        self.cookie = cookie
        self.refresh_token = refresh_token
        self.access_token = access_token
        self.drive_id = drive_id
        self.base_url = "https://api.aliyundrive.com"
        self.web_url = "https://www.aliyundrive.com"
        
        # ä¼˜å…ˆçº§ï¼šaccess_token > refresh_token > cookie
        if access_token and drive_id:
            # ç›´æ¥ä½¿ç”¨æä¾›çš„ access_token å’Œ drive_id
            logger.info("ä½¿ç”¨ Access Token è®¤è¯é˜¿é‡Œäº‘ç›˜")
            self._verify_access_token()
        elif refresh_token:
            # ä½¿ç”¨ refresh_token è·å– access_token
            logger.info("ä½¿ç”¨ Refresh Token è®¤è¯é˜¿é‡Œäº‘ç›˜")
            self._refresh_access_token()
        elif cookie:
            # å°è¯•ä» Cookie ä¸­æå–æˆ–ä½¿ç”¨ Cookie è®¤è¯
            logger.info("å°è¯•ä½¿ç”¨ Cookie è®¤è¯é˜¿é‡Œäº‘ç›˜")
            success = self._extract_token_from_cookie()
            if not success:
                raise ValueError("Cookie è®¤è¯å¤±è´¥ï¼Œå»ºè®®ä½¿ç”¨ refresh_token æˆ– access_token")
        else:
            raise ValueError("å¿…é¡»æä¾› access_token+drive_idã€refresh_token æˆ– cookie ä¹‹ä¸€")
    
    def _verify_access_token(self):
        """éªŒè¯ Access Token æ˜¯å¦æœ‰æ•ˆ"""
        try:
            url = f"{self.base_url}/v2/user/get"
            headers = {
                "Authorization": f"Bearer {self.access_token}",
                "Content-Type": "application/json"
            }
            
            response = requests.post(url, headers=headers, json={}, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                # å¦‚æœæ²¡æœ‰æä¾› drive_idï¼Œä»å“åº”ä¸­è·å–
                if not self.drive_id:
                    self.drive_id = result.get("default_drive_id")
                logger.info(f"Access Token éªŒè¯æˆåŠŸï¼Œç”¨æˆ·: {result.get('nick_name', 'N/A')}")
            else:
                logger.error(f"Access Token éªŒè¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                raise ValueError("Access Token æ— æ•ˆæˆ–å·²è¿‡æœŸ")
        except Exception as e:
            logger.error(f"éªŒè¯ Access Token å¤±è´¥: {str(e)}")
            raise
    
    def _extract_token_from_cookie(self) -> bool:
        """ä» Cookie ä¸­æå– token ä¿¡æ¯æˆ–ç›´æ¥ä½¿ç”¨ Cookie è®¤è¯"""
        try:
            logger.info("å°è¯•ä½¿ç”¨ Cookie è®¤è¯é˜¿é‡Œäº‘ç›˜...")
            
            # æ–¹æ³•1: å°è¯•ä» Cookie ä¸­æå– token å­—æ®µ
            # æœ‰äº›æµè§ˆå™¨æ’ä»¶ä¼šå°† token å­˜å…¥ Cookie
            token_found = False
            for item in self.cookie.split(';'):
                item = item.strip()
                if item.startswith('token=') or item.startswith('refresh_token='):
                    token_value = item.split('=', 1)[1]
                    if len(token_value) > 50:  # token é€šå¸¸å¾ˆé•¿
                        self.refresh_token = token_value
                        logger.info("ä» Cookie ä¸­æå–åˆ° refresh_token")
                        return self._refresh_access_token()
            
            # æ–¹æ³•2: å°è¯•é€šè¿‡ Cookie ç›´æ¥è®¿é—® API
            # è·å–ç”¨æˆ·ä¿¡æ¯å’Œ drive_id
            url = f"{self.base_url}/v2/user/get"
            headers = {
                "Cookie": self.cookie,
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Content-Type": "application/json"
            }
            
            response = requests.post(url, headers=headers, json={}, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                self.drive_id = result.get("default_drive_id")
                
                if self.drive_id:
                    logger.info("é€šè¿‡ Cookie è·å–ç”¨æˆ·ä¿¡æ¯æˆåŠŸ")
                    # å°è¯•ä»å“åº”å¤´æˆ–å…¶ä»–åœ°æ–¹è·å– access_token
                    # æ³¨æ„ï¼šè¿™ç§æ–¹å¼å¯èƒ½ä¸ç¨³å®šï¼Œå»ºè®®ä½¿ç”¨ refresh_token
                    return True
                else:
                    logger.warning("æœªèƒ½è·å– drive_id")
                    return False
            else:
                logger.warning(f"Cookie è®¤è¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                logger.info("å»ºè®®ä½¿ç”¨ refresh_token æ–¹å¼ï¼Œæ›´ç¨³å®šå¯é ")
                return False
                
        except Exception as e:
            logger.error(f"Cookie è®¤è¯å¤±è´¥: {str(e)}")
            logger.info("å»ºè®®ä½¿ç”¨ refresh_token æ–¹å¼")
            return False
        
    def _refresh_access_token(self):
        """åˆ·æ–°è®¿é—®ä»¤ç‰Œ"""
        url = f"{self.base_url}/token/refresh"
        data = {
            "refresh_token": self.refresh_token
        }
        
        try:
            response = requests.post(url, json=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            
            self.access_token = result.get("access_token")
            self.refresh_token = result.get("refresh_token")
            self.drive_id = result.get("default_drive_id")
            
            logger.info("é˜¿é‡Œäº‘ç›˜ä»¤ç‰Œåˆ·æ–°æˆåŠŸ")
        except Exception as e:
            logger.error(f"é˜¿é‡Œäº‘ç›˜ä»¤ç‰Œåˆ·æ–°å¤±è´¥: {str(e)}")
            raise
    
    def _get_headers(self) -> Dict:
        """è·å–è¯·æ±‚å¤´"""
        headers = {
            "Content-Type": "application/json",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        if self.access_token:
            headers["Authorization"] = f"Bearer {self.access_token}"
        
        if self.cookie:
            headers["Cookie"] = self.cookie
            
        return headers
    
    def get_file_by_path(self, file_path: str) -> Optional[Dict]:
        """æ ¹æ®è·¯å¾„è·å–æ–‡ä»¶ä¿¡æ¯"""
        url = f"{self.base_url}/v2/file/get_by_path"
        data = {
            "drive_id": self.drive_id,
            "file_path": file_path
        }
        
        try:
            response = requests.post(url, json=data, headers=self._get_headers(), timeout=30)
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 404:
                logger.debug(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            else:
                logger.debug(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {file_path}, çŠ¶æ€ç : {response.status_code}")
                return None
        except Exception as e:
            logger.debug(f"è·å–æ–‡ä»¶ä¿¡æ¯å¼‚å¸¸: {file_path}, {str(e)}")
            return None
    
    def create_folder(self, parent_file_id: str, folder_name: str) -> Optional[str]:
        """åˆ›å»ºæ–‡ä»¶å¤¹"""
        url = f"{self.base_url}/adrive/v2/file/createWithFolders"
        data = {
            "drive_id": self.drive_id,
            "parent_file_id": parent_file_id,
            "name": folder_name,
            "check_name_mode": "auto_rename",  # æ”¹ä¸ºè‡ªåŠ¨é‡å‘½åï¼Œé¿å…å†²çª
            "type": "folder"
        }
        
        try:
            response = requests.post(url, json=data, headers=self._get_headers(), timeout=30)
            
            # è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            # 201 Created ä¹Ÿæ˜¯æˆåŠŸçŠ¶æ€
            if response.status_code not in [200, 201]:
                error_msg = f"çŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}"
                logger.error(f"æ–‡ä»¶å¤¹åˆ›å»ºå¤±è´¥ '{folder_name}': {error_msg}")
                
                # å°è¯•è§£æé”™è¯¯ä¿¡æ¯
                try:
                    error_data = response.json()
                    if error_data.get("code") == "AlreadyExist.File":
                        logger.info(f"æ–‡ä»¶å¤¹å·²å­˜åœ¨: {folder_name}ï¼Œå°è¯•è·å–...")
                        # æ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œå°è¯•é€šè¿‡åˆ—è¡¨è·å–
                        return self._get_folder_id_by_name(parent_file_id, folder_name)
                except:
                    pass
                
                return None
            
            result = response.json()
            file_id = result.get("file_id")
            logger.info(f"æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸ: {folder_name} (ID: {file_id})")
            return file_id
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤¹åˆ›å»ºå¼‚å¸¸ '{folder_name}': {str(e)}")
            return None
    
    def _get_folder_id_by_name(self, parent_file_id: str, folder_name: str) -> Optional[str]:
        """é€šè¿‡åç§°è·å–æ–‡ä»¶å¤¹ID"""
        try:
            url = f"{self.base_url}/adrive/v3/file/list"
            data = {
                "drive_id": self.drive_id,
                "parent_file_id": parent_file_id,
                "limit": 100,
                "type": "folder"
            }
            
            response = requests.post(url, json=data, headers=self._get_headers(), timeout=30)
            if response.status_code == 200:
                result = response.json()
                items = result.get("items", [])
                for item in items:
                    if item.get("name") == folder_name:
                        return item.get("file_id")
            return None
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤¹IDå¤±è´¥: {str(e)}")
            return None
    
    def create_file(self, parent_file_id: str, file_name: str, file_size: int) -> Optional[Dict]:
        """åˆ›å»ºæ–‡ä»¶ï¼ˆè·å–ä¸Šä¼ URLï¼‰"""
        url = f"{self.base_url}/adrive/v2/file/createWithFolders"
        
        # è®¡ç®—æ–‡ä»¶çš„é¢„åˆ›å»ºhashï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        data = {
            "drive_id": self.drive_id,
            "parent_file_id": parent_file_id,
            "name": file_name,
            "type": "file",
            "check_name_mode": "auto_rename",
            "size": file_size,
            "part_info_list": [{"part_number": 1}]
        }
        
        try:
            response = requests.post(url, json=data, headers=self._get_headers(), timeout=30)
            response.raise_for_status()
            result = response.json()
            
            return result
        except Exception as e:
            logger.error(f"æ–‡ä»¶åˆ›å»ºå¤±è´¥ {file_name}: {str(e)}")
            return None
    
    def upload_file(self, local_path: str, parent_file_id: str, file_name: str) -> bool:
        """ä¸Šä¼ æ–‡ä»¶"""
        file_size = os.path.getsize(local_path)
        
        # åˆ›å»ºæ–‡ä»¶
        create_result = self.create_file(parent_file_id, file_name, file_size)
        if not create_result:
            return False
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼ˆç§’ä¼ ï¼‰
        if create_result.get("rapid_upload"):
            logger.info(f"æ–‡ä»¶ç§’ä¼ æˆåŠŸ: {file_name}")
            return True
        
        # è·å–ä¸Šä¼ URL
        upload_url = create_result.get("part_info_list", [{}])[0].get("upload_url")
        if not upload_url:
            logger.error(f"æœªè·å–åˆ°ä¸Šä¼ URL: {file_name}")
            return False
        
        file_id = create_result.get("file_id")
        upload_id = create_result.get("upload_id")
        
        # ä¸Šä¼ æ–‡ä»¶å†…å®¹
        try:
            with open(local_path, 'rb') as f:
                file_data = f.read()
            
            headers = {
                "Content-Type": ""
            }
            response = requests.put(upload_url, data=file_data, headers=headers, timeout=300)
            response.raise_for_status()
            
            # å®Œæˆä¸Šä¼ 
            complete_url = f"{self.base_url}/v2/file/complete"
            complete_data = {
                "drive_id": self.drive_id,
                "file_id": file_id,
                "upload_id": upload_id
            }
            
            response = requests.post(complete_url, json=complete_data, 
                                    headers=self._get_headers(), timeout=30)
            response.raise_for_status()
            
            logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_name}")
            return True
        except Exception as e:
            logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥ {file_name}: {str(e)}")
            return False
    
    def get_or_create_folder_by_path(self, folder_path: str) -> Optional[str]:
        """æ ¹æ®è·¯å¾„è·å–æˆ–åˆ›å»ºæ–‡ä»¶å¤¹ï¼Œè¿”å›æ–‡ä»¶å¤¹ID"""
        logger.debug(f"è·å–/åˆ›å»ºæ–‡ä»¶å¤¹: {folder_path}")
        
        # è§„èŒƒåŒ–è·¯å¾„
        folder_path = folder_path.strip()
        if folder_path == "/" or folder_path == "" or folder_path == ".":
            logger.debug("è¿”å›æ ¹ç›®å½• ID: root")
            return "root"
        
        # ç§»é™¤å¼€å¤´çš„æ–œæ 
        folder_path = folder_path.lstrip("/")
        
        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        logger.debug(f"æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨: /{folder_path}")
        existing = self.get_file_by_path(f"/{folder_path}")
        if existing:
            file_id = existing.get("file_id")
            logger.debug(f"æ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼ŒID: {file_id}")
            return file_id
        
        # åˆ†å‰²è·¯å¾„ï¼Œé€å±‚åˆ›å»º
        parts = folder_path.split("/")
        current_path = ""
        current_parent_id = "root"
        
        for part in parts:
            if not part:
                continue
            
            current_path = f"{current_path}/{part}" if current_path else part
            full_path = f"/{current_path}"
            
            logger.debug(f"å¤„ç†è·¯å¾„: {full_path}")
            
            # æ£€æŸ¥å½“å‰å±‚æ˜¯å¦å­˜åœ¨
            existing = self.get_file_by_path(full_path)
            if existing:
                current_parent_id = existing.get("file_id")
                logger.debug(f"æ–‡ä»¶å¤¹å·²å­˜åœ¨: {part}, ID: {current_parent_id}")
            else:
                # åˆ›å»ºå½“å‰å±‚
                logger.debug(f"åˆ›å»ºæ–‡ä»¶å¤¹: {part} (çˆ¶ID: {current_parent_id})")
                folder_id = self.create_folder(current_parent_id, part)
                if not folder_id:
                    logger.error(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {part}")
                    return None
                current_parent_id = folder_id
        
        return current_parent_id


class BaiduToAliyunSync:
    """ç™¾åº¦äº‘ç›˜åˆ°é˜¿é‡Œäº‘ç›˜åŒæ­¥å™¨"""
    
    def __init__(self, baidu_config: Dict, aliyun_config: Dict, temp_dir: str = "/tmp/pan_sync"):
        """
        åˆå§‹åŒ–åŒæ­¥å™¨
        :param baidu_config: ç™¾åº¦ç½‘ç›˜é…ç½® {"cookie": "..."} æˆ– {"access_token": "..."}
        :param aliyun_config: é˜¿é‡Œäº‘ç›˜é…ç½®ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
            - {"access_token": "...", "drive_id": "..."}  # æ¨èï¼šç›´æ¥ä½¿ç”¨ Bearer Token
            - {"refresh_token": "..."}  # æ¨èï¼šä½¿ç”¨ Refresh Token
            - {"cookie": "..."}  # å¤‡ç”¨ï¼šä½¿ç”¨ Cookie
        """
        # åˆå§‹åŒ–ç™¾åº¦ç½‘ç›˜å®¢æˆ·ç«¯
        if "cookie" in baidu_config and USE_BAIDUPCS:
            # ä¼˜å…ˆä½¿ç”¨ baidupcs-pyï¼ˆå¯ä»¥ç»•è¿‡ä¸‹è½½é™åˆ¶ï¼‰
            logger.info("ä½¿ç”¨ baidupcs-py å®¢æˆ·ç«¯")
            self.baidu_client = BaiduPanClientPCS(cookie=baidu_config["cookie"])
        elif "cookie" in baidu_config:
            self.baidu_client = BaiduPanClient(cookie=baidu_config["cookie"])
        else:
            self.baidu_client = BaiduPanClient(access_token=baidu_config.get("access_token"))
        
        # åˆå§‹åŒ–é˜¿é‡Œäº‘ç›˜å®¢æˆ·ç«¯
        if "access_token" in aliyun_config:
            # ä½¿ç”¨ Access Token + Drive ID æ–¹å¼
            self.aliyun_client = AliyunPanClient(
                access_token=aliyun_config["access_token"],
                drive_id=aliyun_config.get("drive_id")
            )
        elif "refresh_token" in aliyun_config:
            # ä½¿ç”¨ Refresh Token æ–¹å¼
            self.aliyun_client = AliyunPanClient(refresh_token=aliyun_config["refresh_token"])
        elif "cookie" in aliyun_config:
            # ä½¿ç”¨ Cookie æ–¹å¼
            self.aliyun_client = AliyunPanClient(cookie=aliyun_config["cookie"])
        else:
            raise ValueError("é˜¿é‡Œäº‘ç›˜é…ç½®å¿…é¡»åŒ…å« access_tokenã€refresh_token æˆ– cookie")
        
        self.temp_dir = temp_dir
        os.makedirs(temp_dir, exist_ok=True)
        
        # æ–­ç‚¹ç»­ä¼ ï¼šè®°å½•å·²å®Œæˆçš„æ–‡ä»¶
        self.progress_file = os.path.join(temp_dir, ".sync_progress.pkl")
        self.completed_files: Set[str] = self._load_progress()
    
    def _load_progress(self) -> Set[str]:
        """åŠ è½½åŒæ­¥è¿›åº¦"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'rb') as f:
                    progress = pickle.load(f)
                logger.info(f"åŠ è½½æ–­ç‚¹ç»­ä¼ è®°å½•: {len(progress)} ä¸ªå·²å®Œæˆæ–‡ä»¶")
                return progress
            except Exception as e:
                logger.warning(f"åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {str(e)}")
        return set()
    
    def _save_progress(self):
        """ä¿å­˜åŒæ­¥è¿›åº¦"""
        try:
            with open(self.progress_file, 'wb') as f:
                pickle.dump(self.completed_files, f)
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åº¦æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _mark_completed(self, file_path: str):
        """æ ‡è®°æ–‡ä»¶ä¸ºå·²å®Œæˆ"""
        self.completed_files.add(file_path)
        self._save_progress()
    
    def _is_completed(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å®Œæˆ"""
        return file_path in self.completed_files
        
    def sync_folder(self, baidu_folder: str, aliyun_folder: str, max_workers: int = 3):
        """
        æµå¼åŒæ­¥æ–‡ä»¶å¤¹ï¼ˆä¸é¢„å…ˆç»Ÿè®¡ï¼Œè¾¹æ‰«æè¾¹åŒæ­¥ï¼‰
        æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        """
        logger.info(f"å¼€å§‹åŒæ­¥: {baidu_folder} -> {aliyun_folder}")
        logger.info(f"å¹¶å‘æ•°: {max_workers}")
        
        # ç¡®ä¿é˜¿é‡Œäº‘ç›˜ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
        logger.info(f"æ£€æŸ¥ç›®æ ‡æ–‡ä»¶å¤¹: {aliyun_folder}")
        target_folder_id = self.aliyun_client.get_or_create_folder_by_path(aliyun_folder)
        if not target_folder_id:
            logger.error("æ— æ³•åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹")
            return
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        success_count = 0
        fail_count = 0
        skip_count = 0
        
        # æµå¼å¤„ç†ï¼šè¾¹æ‰«æè¾¹åŒæ­¥
        logger.info("å¼€å§‹æµå¼æ‰«æå’ŒåŒæ­¥...")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            
            # é€’å½’å¤„ç†ç›®å½•
            def process_directory(dir_path: str, target_base: str):
                nonlocal success_count, fail_count, skip_count
                
                logger.info(f"ğŸ“ æ‰«æç›®å½•: {dir_path}")
                
                # è·å–å½“å‰ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆä¸é€’å½’ï¼‰
                items = self.baidu_client.list_files(dir_path, recursion=0)
                
                if not items:
                    logger.debug(f"ç›®å½•ä¸ºç©º: {dir_path}")
                    return
                
                # åˆ†ç±»æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
                folders = [f for f in items if f.get("isdir") == 1]
                files = [f for f in items if f.get("isdir") == 0]
                
                logger.info(f"  å‘ç°: {len(files)} ä¸ªæ–‡ä»¶, {len(folders)} ä¸ªå­æ–‡ä»¶å¤¹")
                
                # å¤„ç†æ–‡ä»¶
                for file_info in files:
                    file_path = file_info.get("path")
                    file_name = file_info.get("server_filename")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
                    if self._is_completed(file_path):
                        skip_count += 1
                        logger.info(f"â­ï¸  è·³è¿‡å·²å®Œæˆ: {file_name} (æ€»è®¡è·³è¿‡: {skip_count})")
                        continue
                    
                    # æäº¤åŒæ­¥ä»»åŠ¡
                    logger.info(f"ğŸ“¤ æäº¤ä»»åŠ¡: {file_name}")
                    future = executor.submit(
                        self._sync_single_file, 
                        file_info, 
                        baidu_folder, 
                        aliyun_folder
                    )
                    futures[future] = file_info
                
                # é€’å½’å¤„ç†å­æ–‡ä»¶å¤¹
                for folder in folders:
                    folder_path = folder.get("path")
                    folder_name = folder.get("server_filename")
                    
                    # è®¡ç®—é˜¿é‡Œäº‘ç›˜è·¯å¾„
                    relative_path = folder_path.replace(baidu_folder, "").lstrip("/")
                    aliyun_path = os.path.join(aliyun_folder, relative_path).replace("\\", "/")
                    
                    # åˆ›å»ºæ–‡ä»¶å¤¹
                    logger.info(f"ğŸ“ åˆ›å»ºæ–‡ä»¶å¤¹: {folder_name}")
                    self.aliyun_client.get_or_create_folder_by_path(aliyun_path)
                    
                    # é€’å½’å¤„ç†å­ç›®å½•
                    process_directory(folder_path, aliyun_folder)
            
            # å¼€å§‹å¤„ç†æ ¹ç›®å½•
            process_directory(baidu_folder, aliyun_folder)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            if futures:
                logger.info(f"ç­‰å¾… {len(futures)} ä¸ªæ–‡ä»¶åŒæ­¥ä»»åŠ¡å®Œæˆ...")
                
                for future in as_completed(futures):
                    file_info = futures[future]
                    file_name = file_info.get("server_filename")
                    
                    try:
                        if future.result():
                            success_count += 1
                            logger.info(f"âœ… å®Œæˆ: {file_name} (æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, è·³è¿‡: {skip_count})")
                        else:
                            fail_count += 1
                            logger.warning(f"âŒ å¤±è´¥: {file_name} (æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, è·³è¿‡: {skip_count})")
                    except Exception as e:
                        fail_count += 1
                        logger.error(f"âŒ å¼‚å¸¸: {file_name} - {str(e)}")
        
        # æœ€ç»ˆç»Ÿè®¡
        logger.info("=" * 60)
        logger.info(f"åŒæ­¥å®Œæˆï¼")
        logger.info(f"  âœ… æˆåŠŸ: {success_count}")
        logger.info(f"  âŒ å¤±è´¥: {fail_count}")
        logger.info(f"  â­ï¸  è·³è¿‡: {skip_count}")
        logger.info(f"  ğŸ“Š æ€»è®¡: {success_count + fail_count + skip_count}")
        logger.info("=" * 60)
    
    def _sync_single_file(self, file_info: Dict, baidu_base: str, aliyun_base: str) -> bool:
        """åŒæ­¥å•ä¸ªæ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        file_path = file_info.get("path")
        file_name = file_info.get("server_filename")
        fs_id = file_info.get("fs_id")
        file_size = file_info.get("size", 0)
        
        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        size_mb = file_size / (1024 * 1024)
        size_str = f"{size_mb:.2f}MB" if size_mb >= 1 else f"{file_size / 1024:.2f}KB"
        
        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        relative_path = file_path.replace(baidu_base, "").lstrip("/")
        relative_dir = os.path.dirname(relative_path)
        
        # è®¡ç®—é˜¿é‡Œäº‘ç›˜è·¯å¾„
        if relative_dir:
            aliyun_dir = os.path.join(aliyun_base, relative_dir).replace("\\", "/")
        else:
            aliyun_dir = aliyun_base
        
        aliyun_file_path = os.path.join(aliyun_dir, file_name).replace("\\", "/")
        
        logger.info(f"ğŸ”„ åŒæ­¥: {file_name} ({size_str})")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        existing_file = self.aliyun_client.get_file_by_path(aliyun_file_path)
        if existing_file:
            logger.info(f"  æ–‡ä»¶å·²å­˜åœ¨äºé˜¿é‡Œäº‘ç›˜ï¼Œæ ‡è®°ä¸ºå®Œæˆ")
            self._mark_completed(file_path)
            return True
        
        # ä¸‹è½½åˆ°ä¸´æ—¶ç›®å½•
        temp_file = os.path.join(self.temp_dir, f"{fs_id}_{file_name}")
        logger.info(f"  â¬‡ï¸  ä¸‹è½½ä¸­...")
        
        # æ ¹æ®å®¢æˆ·ç«¯ç±»å‹é€‰æ‹©ä¸‹è½½æ–¹å¼
        if USE_BAIDUPCS and isinstance(self.baidu_client, BaiduPanClientPCS):
            # ä½¿ç”¨ baidupcs-py ç›´æ¥ä¸‹è½½
            if not self.baidu_client.download_file(file_path, temp_file):
                return False
        else:
            # ä½¿ç”¨åŸå§‹æ–¹æ³•ï¼šå…ˆè·å–ä¸‹è½½é“¾æ¥ï¼Œå†ä¸‹è½½
            logger.debug(f"  è·å–ä¸‹è½½é“¾æ¥...")
            download_url = self.baidu_client.get_download_link(fs_id)
            if not download_url:
                logger.error(f"  âŒ æ— æ³•è·å–ä¸‹è½½é“¾æ¥")
                return False
            
            if not self.baidu_client.download_file(download_url, temp_file):
                return False
        
        # è·å–é˜¿é‡Œäº‘ç›˜çˆ¶æ–‡ä»¶å¤¹ID
        logger.debug(f"  è·å–çˆ¶æ–‡ä»¶å¤¹ ID...")
        parent_folder_id = self.aliyun_client.get_or_create_folder_by_path(aliyun_dir)
        if not parent_folder_id:
            logger.error(f"  âŒ æ— æ³•åˆ›å»ºçˆ¶æ–‡ä»¶å¤¹: {aliyun_dir}")
            try:
                os.remove(temp_file)
            except:
                pass
            return False
        
        # ä¸Šä¼ åˆ°é˜¿é‡Œäº‘ç›˜
        logger.info(f"  â¬†ï¸  ä¸Šä¼ ä¸­...")
        success = self.aliyun_client.upload_file(temp_file, parent_folder_id, file_name)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(temp_file)
        except:
            pass
        
        # æ ‡è®°ä¸ºå·²å®Œæˆï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
        if success:
            self._mark_completed(file_path)
            logger.info(f"  âœ… åŒæ­¥æˆåŠŸ")
        else:
            logger.error(f"  âŒ åŒæ­¥å¤±è´¥")
        
        return success


def load_config(config_file: str = "config.json") -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not os.path.exists(config_file):
        logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return {}
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        return {}


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½é…ç½®
    config = load_config()
    
    if not config:
        logger.error("è¯·åˆ›å»º config.json é…ç½®æ–‡ä»¶")
        print("\né…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼ˆæ¨èä½¿ç”¨ Cookie æ–¹å¼ï¼‰:")
        print(json.dumps({
            "baidu": {
                "cookie": "ä½ çš„ç™¾åº¦ç½‘ç›˜Cookieï¼ˆæ¨èï¼‰"
            },
            "aliyun": {
                "refresh_token": "ä½ çš„é˜¿é‡Œäº‘ç›˜refresh_tokenï¼ˆæ¨èï¼‰"
            },
            "sync_tasks": [
                {
                    "baidu_folder": "/æˆ‘çš„æ–‡ä»¶å¤¹",
                    "aliyun_folder": "/å¤‡ä»½/æˆ‘çš„æ–‡ä»¶å¤¹"
                }
            ],
            "temp_dir": "/tmp/pan_sync",
            "max_workers": 3
        }, indent=2, ensure_ascii=False))
        print("\næˆ–ä½¿ç”¨æ—§ç‰ˆé…ç½®æ ¼å¼:")
        print(json.dumps({
            "baidu_cookie": "ä½ çš„ç™¾åº¦ç½‘ç›˜Cookie",
            "aliyun_refresh_token": "ä½ çš„é˜¿é‡Œäº‘ç›˜refresh_token",
            "sync_tasks": [
                {
                    "baidu_folder": "/æˆ‘çš„æ–‡ä»¶å¤¹",
                    "aliyun_folder": "/å¤‡ä»½/æˆ‘çš„æ–‡ä»¶å¤¹"
                }
            ]
        }, indent=2, ensure_ascii=False))
        return
    
    # è·å–é…ç½®å‚æ•°ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼ï¼‰
    sync_tasks = config.get("sync_tasks", [])
    temp_dir = config.get("temp_dir", "/tmp/pan_sync")
    max_workers = config.get("max_workers", 3)
    
    # è§£æç™¾åº¦ç½‘ç›˜é…ç½®
    baidu_config = {}
    if "baidu" in config:
        baidu_config = config["baidu"]
    elif "baidu_cookie" in config:
        baidu_config = {"cookie": config["baidu_cookie"]}
    elif "baidu_access_token" in config:
        baidu_config = {"access_token": config["baidu_access_token"]}
    
    # è§£æé˜¿é‡Œäº‘ç›˜é…ç½®
    aliyun_config = {}
    if "aliyun" in config:
        aliyun_config = config["aliyun"]
    elif "aliyun_access_token" in config:
        # æ”¯æŒç›´æ¥ä½¿ç”¨ access_token
        aliyun_config = {
            "access_token": config["aliyun_access_token"],
            "drive_id": config.get("aliyun_drive_id")
        }
    elif "aliyun_cookie" in config:
        aliyun_config = {"cookie": config["aliyun_cookie"]}
    elif "aliyun_refresh_token" in config:
        aliyun_config = {"refresh_token": config["aliyun_refresh_token"]}
    
    if not baidu_config or not aliyun_config:
        logger.error("è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ç™¾åº¦ç½‘ç›˜å’Œé˜¿é‡Œäº‘ç›˜çš„è®¤è¯ä¿¡æ¯")
        return
    
    if not sync_tasks:
        logger.error("è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® sync_tasks")
        return
    
    # åˆ›å»ºåŒæ­¥å™¨
    try:
        syncer = BaiduToAliyunSync(baidu_config, aliyun_config, temp_dir)
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–åŒæ­¥å™¨å¤±è´¥: {str(e)}")
        return
    
    # æ‰§è¡ŒåŒæ­¥ä»»åŠ¡
    for task in sync_tasks:
        baidu_folder = task.get("baidu_folder")
        aliyun_folder = task.get("aliyun_folder")
        
        if not baidu_folder or not aliyun_folder:
            logger.warning(f"è·³è¿‡æ— æ•ˆä»»åŠ¡: {task}")
            continue
        
        try:
            syncer.sync_folder(baidu_folder, aliyun_folder, max_workers)
        except Exception as e:
            logger.error(f"åŒæ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    logger.info("æ‰€æœ‰åŒæ­¥ä»»åŠ¡å®Œæˆ")


if __name__ == "__main__":
    main()
